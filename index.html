<!DOCTYPE html>
<html lang="en">

  <head>

    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <!-- <meta name="viewport" content="width=device-width, initial-scale=1"> -->
    <meta name="viewport" content="width=1024">

    <title>RSS 2020 VLRRM Workshop</title>

    <link rel="icon" type="image/png" href="images/robot_emoji.png">

    <!-- bootstrap -->
    <link rel="stylesheet" href="./files/bootstrap.min.css">
    <link rel="stylesheet" href="./files/bootstrap-theme.min.css">
    <link rel="stylesheet" type="text/css" href="./files/style.css">

    <!-- Google fonts -->
    <link href="./files/google-fonts.css" rel="stylesheet" type="text/css">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-47054450-13"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-47054450-13');
    </script>

  </head>


  <body>

    <div class="container-fluid">

      <!-- <div> -->
      <!--   <a href="http://svl.stanford.edu/"> -->
      <!--     <img src="./images/rss_2020.png" class="img-logo"> -->
      <!--   </a> -->
      <!-- </div> -->

      <div class="row section">
        <div class="text-center">
          <h2 style="color:#8c1515">Visual Learning and Reasoning for Robotic Manipulation</h2>
          </br>
          <h4>Full-day workshop at <a href="https://roboticsconference.org/">RSS 2020</a></h4>
          <h4>Oregon State University at Corvallis, Oregon, USA</h4>
          <h4>July 13, 2020, <a href="https://greenwichmeantime.com/time-zone/usa/pacific-time/" target="_blank">Pacific Time (PT)</a></h4>
          <hr>
        </div>
      </div>

      <div class="row section">
        <div class="text-justify">
          Welcome! Please attend our virtual workshop via <a href="https://pheedloop.com/rss2020/virtual/" target="_blank">this link</a>.
          <br><br>
          This workshop includes three live events:
          <ul>
            <li><b>Invited Talks</b> (25 min talk + 5 min Q&A)</li>
            <li><b>Spotlight Talks</b> (4 &times; 5 min pre-recorded videos + 10 min Q&A)</li>
            <li><b>Panel Discussion</b> (60 min)</li>
          </ul>
        </div>
      </div>

      <div class="row section">
        <div>
          <center><h3>Schedule</h3><hr></center>

          <table>
            <thead>
              <tr>
                <th class="time">Time (<a href="https://greenwichmeantime.com/time-zone/usa/pacific-time/" target="_blank">PT</a>)</th>
                <th class="speaker">Invited Speaker</th>
                <th class="title">Title</th>
              </tr>
            </thead>

            <tbody>
              <tr class="highlight">
                <td class="time">9:15 - 9:30</td>
                <td class="speaker">-</td>
                <td class="title">Opening Remarks</td>
              </tr>

              <tr>
                <td class="time">9:30 - 10:00</td>
                <td class="speaker">
                  <a href="https://www.cis.upenn.edu/~kostas/" target="_blank"><img src="photos/kostas.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  </br></br>
                  <a href="https://www.cis.upenn.edu/~kostas/" target="_blank">Kostas Daniilidis</a>
                  </br>
                  University of Pennsylvania
                </td>
                <td class="title">The Curious Explorer</td>
                <!-- <td class="title"><a href="">The Curious Explorer</a></td> -->
              </tr>

              <tr class="highlight">
                <td class="time">10:00 - 10:30</td>
                <td class="speaker">
                  <a href="https://www.cs.princeton.edu/~funk/" target="_blank"><img src="photos/tom.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  </br></br>
                  <a href="https://www.cs.princeton.edu/~funk/" target="_blank">Thomas Funkhouser</a>
                  </br>
                  Google Research
                </td>
                <td class="title">Spatial Action Maps</td>
                <!-- <td class="title"><a href="">Spatial Action Maps</a></td> -->
              </tr>

              <tr>
                <td class="time">10:30 - 11:00</td>
                <td class="speaker">
                  Spotlight Talks<br>+<br>Q&A
                </td>
                <td class="title">
                  <a href="papers/3_CameraReadySubmission_RSS_workshop_latent_space_roadmap.pdf">Latent Space Roadmap for Visual Action Planning</a>
                  </br>
                  <small>
                    Martina Lippi (University of Salerno); Petra Poklukar (KTH); Michael Welle (KTH); Anastasiia Varava (KTH); Hang Yin (KTH); Alessandro Marino (University of Cassino and Southern Lazio); Danica Kragic (KTH)
                  </small>
                  </br>
                  <center>
                    <a href="papers/3_CameraReadySubmission_RSS_workshop_latent_space_roadmap.pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/HkPZEP1W5eQ" target="_blank">Video</a>
                  </center>
                  </br></br>

                  <a href="papers/5_CameraReadySubmission_revisit_grasp_map_CRV.pdf">Revisiting Grasp Map Representation with a Focus on Orientation in Grasp Synthesis</a>
                  </br>
                  <small>
                    Nikolaos Gkanatsios (DeepLab); Georgia Chalvatzaki (TU Darmstadt); Petros Maragos (National Technical University of Athens); Jan Peters (TU Darmstadt + Max Planck Institute for Intelligent Systems)
                  </small>
                  </br>
                  <center>
                    <a href="papers/5_CameraReadySubmission_revisit_grasp_map_CRV.pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/iMY0_J7-fJc" target="_blank">Video</a>
                  </center>
                  </br></br>

                  <a href="papers/11_CameraReadySubmission_simple_sensor_intentions_for_exploration_cr.pdf">Simple Sensor Intentions for Exploration</a>
                  </br>
                  <small>
                    Tim Hertweck (DeepMind); Martin Riedmiller (DeepMind); Michael Bloesch (Google); Jost Tobias Springenberg (DeepMind); Noah Siegel (DeepMind); Markus Wulfmeier (DeepMind); Roland Hafner (Google DeepMind); Nicolas Heess (DeepMind)
                  </small>
                  </br>
                  <center>
                    <a href="papers/11_CameraReadySubmission_simple_sensor_intentions_for_exploration_cr.pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/uDWMmpF1MYY" target="_blank">Video</a>
                  </center>
                  </br></br>

                  <a href="papers/6_CameraReadySubmission_GAP_RSS_WS_CR.pdf">Goal-Aware Prediction: Learning to Model What Matters</a>
                  </br>
                  <small>
                    Suraj Nair (Stanford University); Silvio Savarese (Stanford University); Chelsea Finn (Stanford University)
                  </small>
                  </br>
                  <center>
                    <a href="papers/6_CameraReadySubmission_GAP_RSS_WS_CR.pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/gIEQEJyFTOw" target="_blank">Video</a>
                  </center>
                </td>
              </tr>

              <tr class="highlight">
                <td class="time">11:00 - 11:30</td>
                <td class="speaker">
                  <a href="https://www.cc.gatech.edu/~chernova/" target="_blank"><img src="photos/sonia.png" width="120px" align="bottom" style="border-radius: 50%"></a>
                  </br></br>
                  <a href="https://www.cc.gatech.edu/~chernova/" target="_blank">Sonia Chernova</a>
                  </br>
                  Georgia Tech
                </td>
                <td class="title">Semantic Grasping through Wide and Deep Learning</td>
                <!-- <td class="title"><a href=""></a></td> -->
              </tr>

              <tr>
                <td class="time">11:30 - 12:00</td>
                <td class="speaker">
                  <a href="https://groups.csail.mit.edu/locomotion/russt.html" target="_blank"><img src="photos/russ.png" width="120px" align="bottom" style="border-radius: 50%"></a>
                  </br></br>
                  <a href="https://groups.csail.mit.edu/locomotion/russt.html" target="_blank">Russ Tedrake</a>
                  </br>
                  MIT / Toyota Research Institute
                </td>
                <td class="title">Toward Category-Level Manipulation</td>
                <!-- <td class="title"><a href=""></a></td> -->
              </tr>

              <tr class="highlight">
                <td class="time">12:00 - 1:30</td>
                <td class="speaker">
                  -
                </td>
                <td class="title">Lunch Break</td>
              </tr>

              <tr>
                <td class="time">1:30 - 2:00</td>
                <td class="speaker">
                  <a href="https://people.eecs.berkeley.edu/~pabbeel/" target="_blank"><img src="photos/pieter.png" width="120px" align="bottom" style="border-radius: 50%"></a>
                  </br></br>
                  <a href="https://people.eecs.berkeley.edu/~pabbeel/" target="_blank">Pieter Abbeel</a>
                  </br>
                  UC Berkeley
                </td>
                <td class="title">Can Deep Reinforcement Learning from Pixels Be Made as Efficient as from States?</td>
                <!-- <td class="title"><a href=""></a></td> -->
              </tr>

              <tr class="highlight">
                <td class="time">2:00 - 2:30</td>
                <td class="speaker">
                  <a href="https://profiles.stanford.edu/fei-fei-li" target="_blank"><img src="photos/fei-fei.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  </br></br>
                  <a href="https://profiles.stanford.edu/fei-fei-li" target="_blank">Fei-Fei Li</a>
                  </br>
                  Stanford University
                </td>
                <td class="title">Octopus, Kittens & Babies:  From Seeing to Doing</td>
                <!-- <td class="title"><a href=""></a></td> -->
              </tr>

              <tr>
                <td class="time">2:30 - 3:00</td>
                <td class="speaker">
                  Spotlight Talks<br>+<br>Q&A
                </td>
                <td class="title">
                  <a href="papers/8_CameraReadySubmission_Cloth_Region_Segmentation_for_Robust_Grasp_Selection__RSSVLRRM2020_ (12).pdf">Cloth Region Segmentation for Robust Grasp Selection</a>
                  </br>
                  <small>
                    Thomas Weng (Carnegie Mellon University); Jianing Qian (Carnegie Mellon University); Brian Okorn (Carnegie Mellon University); Luxin Zhang (Carnegie Mellon University); David Held (Carnegie Mellon University)
                  </small>
                  <center>
                    <a href="papers/8_CameraReadySubmission_Cloth_Region_Segmentation_for_Robust_Grasp_Selection__RSSVLRRM2020_ (12).pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/mOFefpQC8Rg" target="_blank">Video</a>
                  </center>
                  </br></br>

                  <a href="papers/10_CameraReadySubmission_ActionForBetterPrediction_CameraReady.pdf">Action for Better Prediction</a>
                  </br>
                  <small>
                    Bernadette K Bucher (University of Pennsylvania); Karl Schmeckpeper (University of Pennsylvania); Nikolai Matni (University of Pennsylvania); Kostas Daniilidis (University of Pennsylvania)
                  </small>
                  <center>
                    <a href="papers/10_CameraReadySubmission_ActionForBetterPrediction_CameraReady.pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/gUst6_9WDmA" target="_blank">Video</a>
                  </center>
                  </br></br>

                  <a href="papers/12_CameraReadySubmission_RSS_PQC_3page_abstract_camera_ready.pdf">Learning Visual Servo Policies via Planner Cloning</a>
                  </br>
                  <small>
                    Ulrich Viereck (Northeastern University); Kate Saenko (Boston University); Robert Platt (Northeastern University)
                  </small>
                  <center>
                    <a href="papers/12_CameraReadySubmission_RSS_PQC_3page_abstract_camera_ready.pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/j20K5FPTaXM" target="_blank">Video</a>
                  </center>
                  </br></br>

                  <a href="papers/14_CameraReadySubmission_LearningManipSkills_RSS2020_VLRRM_CameraReady.pdf">Learning to Plan with Point Cloud Affordances for General-Purpose Dexterous Manipulation</a>
                  </br>
                  <small>
                    Anthony Simeonov (MIT); Yilun Du (MIT); Beomjoon Kim (MIT); Francois Hogan (MIT); Alberto Rodriguez (MIT); Pulkit Agrawal (UC Berkeley)
                  </small>
                  <center>
                    <a href="papers/14_CameraReadySubmission_LearningManipSkills_RSS2020_VLRRM_CameraReady.pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/CfC-igMOtOo" target="_blank">Video</a>
                  </center>
                </td>
              </tr>

              <tr class="highlight">
                <td class="time">3:00 - 3:30</td>
                <td class="speaker">
                  Spotlight Talks<br>+<br>Q&A
                </td>
                <td class="title">
                  <a href="papers/7_CameraReadySubmission_Efficient_Adaptation_for_End_to_End_Vision_Based_Robotic_Manipulation__RSS2020_VLRR_compress.pdf">Efficient Adaptation for End-to-End Vision-Based Robotic Manipulation</a>
                  </br>
                  <small>
                    Ryan C Julian (University of Southern California); Benjamin Swanson (Google); Gaurav Sukhatme (University of Southern California); Sergey Levine (Google); Chelsea Finn (Google Brain); Karol Hausman (Google Brain)
                  </small>
                  <center>
                    <a href="papers/7_CameraReadySubmission_Efficient_Adaptation_for_End_to_End_Vision_Based_Robotic_Manipulation__RSS2020_VLRR_compress.pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/O4ysixlkqMY" target="_blank">Video</a>
                  </center>
                  </br></br>

                  <a href="papers/13_CameraReadySubmission_rssclrrm_13.pdf">Self-Supervised Goal-Conditioned Pick and Place</a>
                  </br>
                  <small>
                    Coline M Devin (UC Berkeley); Payam Rowghanian (Osaro); Chris Vigorito (Osaro); Will Richards (Osaro); Khashayar Rohanimanesh (Osaro)
                  </small>
                  <center>
                    <a href="papers/13_CameraReadySubmission_rssclrrm_13.pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/Vf2aRuLkVeE" target="_blank">Video</a>
                  </center>
                  </br></br>

                  <a href="papers/9_CameraReadySubmission_2020_RSS_Workshop(6).pdf">Seeing Through Your Skin: A Novel Visuo-Tactile Sensor for Robotic Manipulation</a>
                  </br>
                  <small>
                    Francois R Hogan (Samsung Electronics), Sahand Rezaei-Shoshtari (Samsung Electronics), Michael Jenkin (Samsung Electronics), Yogesh Girdhar (Samsung Electronics), David Meger (Samsung Electronics), Gregory Dudek (Samsung Electronics)
                  </small>
                  <center>
                    <a href="papers/9_CameraReadySubmission_2020_RSS_Workshop(6).pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/osWYi3sjN20" target="_blank">Video</a>
                  </center>
                  </br></br>

                  <a href="papers/15_CameraReadySubmission_feedback_4page.pdf">kPAM 2.0: Feedback Control for Category-Level Robotic Manipulation</a>
                  </br>
                  <small>
                    Wei Gao (MIT); Russ Tedrake (MIT)
                  </small>
                  <center>
                    <a href="papers/15_CameraReadySubmission_feedback_4page.pdf" target="_blank">PDF</a>
                    |
                    <a href="https://youtu.be/GbblE4BtH08" target="_blank">Video</a>
                  </center>
                </td>
              </tr>

              <tr>
                <td class="time">3:30 - 4:00</td>
                <td class="speaker">
                  <a href="https://homes.cs.washington.edu/~fox/" target="_blank"><img src="photos/dieter.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  </br></br>
                  <a href="https://homes.cs.washington.edu/~fox/" target="_blank">Dieter Fox</a>
                  </br>
                  University of Washington / NVIDIA
                </td>
                <td class="title">Manipulating Known and Unknown Objects</td>
                <!-- <td class="title"><a href=""></a></td> -->
              </tr>

              <tr class="highlight">
                <td class="time">4:00 - 5:00</td>
                <td class="speaker">
                  <a href="https://www.cim.mcgill.ca/~dudek/" target="_blank"><img src="photos/greg.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  </br></br>
                  <a href="https://www.cim.mcgill.ca/~dudek/" target="_blank">Greg Dudek</a> (Moderator)
                  </br>
                  McGill University / Samsung
                  </br>
                  +
                  </br>
                  <a href="https://goldberg.berkeley.edu/" target="_blank"><img src="photos/ken.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                  </br></br>
                  <a href="https://goldberg.berkeley.edu/" target="_blank">Ken Goldberg</a>
                  </br>
                  UC Berkeley
                  </br>
                  +
                  </br>
                  Invited Speakers
                </td>
                <td class="title">Panel Discussion</td>
                <!-- <td class="title"><a href=""></a></td> -->
              </tr>

            </tbody>
          </table>
        </div>
      </div>

      </div>

      <div class="row section">
        <center><h3>Introduction</h3><hr></center>

        Visual perception is essential for achieving robot autonomy in the real world. To perform complex manipulation tasks in unknown environments, a robot needs to actively acquire knowledge through physical interactions and conduct sophisticated reasoning of the observed objects. This invites a series of research challenges in developing computational tools to close the perception-action loop. Given the recent advances in computer vision and deep learning, we look for new potential solutions for performing real-world robotic manipulation in an effective and computationally efficient manner.
        </br></br>
        We focus on the two parallel themes in this workshop:
        <ul>
          <li>How could a robot’s interaction with the physical world facilitate the development of its visual perception?</li>
          <li>How a deep understanding of the physical world through visual learning and reasoning could give rise to effective and robust robotic control?</li>
        </ul>
      </div>

      <div class="row section">
        <center><h3>Call for Papers</h3><hr></center>

        We're inviting submissions! If you're interested in (remotely) presenting a spotlight talk, please submit a short paper (or extended abstract) to <a href="https://cmt3.research.microsoft.com/RSSVLRR2020/" target="_blank">CMT</a>. We suggest extended abstracts of 2 pages in the <a href="https://roboticsconference.org/information/authorinfo/" target="_blank">RSS format</a>. A maximum of 4 pages will be considered. References will not count towards the page limit. The review process is double-blind.
        </br></br>
        Please note that we have a <b>Best Paper Award</b>. The winner will receive a prize sponsored by Samsung.
        </br></br>
        Important Dates:
        <ul>
          <li>Paper Submission: <strike><b>June 8, 2020</b></strike> </li>
          <li>Author Notification: <strike><b>June 29, 2020</b></strike> </li>
          <li>Conference Date: <b>July 13, 2020</b> </li>
        </ul>

      </div>

      <div class="row section">
        <center><h3>Organizers</h3><hr></center>

        <table>
          <tbody>
            <tr>
              <td class="organizer">
                <a href="http://ai.stanford.edu/~kuanfang/" target="_blank"><img src="photos/kuan.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                </br></br>
                <a href="http://ai.stanford.edu/~kuanfang/" target="_blank">Kuan Fang</a>
                </br>
                Stanford University
              </td>

              <td class="organizer">
                <a href="http://davheld.github.io/" target="_blank"><img src="photos/dave.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                </br></br>
                <a href="http://davheld.github.io/" target="_blank">David Held</a>
                </br>
                <!-- Carnegie Mellon University -->
                CMU
              </td>

              <td class="organizer">
                <a href="https://www.cs.utexas.edu/people/faculty-researchers/yuke-zhu" target="_blank"><img src="photos/yuke.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                </br></br>
                <a href="https://www.cs.utexas.edu/people/faculty-researchers/yuke-zhu" target="_blank">Yuke Zhu</a>
                </br>
                UT Austin / NVIDIA
              </td>

              <td class="organizer">
                <a href="https://www.seas.upenn.edu/~dineshj/" target="_blank"><img src="photos/dinesh.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                </br></br>
                <a href="https://www.seas.upenn.edu/~dineshj/" target="_blank">Dinesh Jayaraman</a>
                </br>
                <!-- University of Pennsylvania -->
                Univ. of Pennsylvania
                <!-- UPenn -->
              </td>
            </tr>

            <tr>
              <td class="organizer">
                <a href="https://animesh.garg.tech/" target="_blank"><img src="photos/animesh.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                </br></br>
                <a href="https://animesh.garg.tech/" target="_blank">Animesh Garg</a>
                </br>
                Univ. of Toronto / NVIDIA
              </td>

              <td class="organizer">
                <a href="https://scholar.google.com/citations?user=iC8zGqEAAAAJ&hl=en" target="_blank"><img src="photos/lin.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                </br></br>
                <a href="https://scholar.google.com/citations?user=iC8zGqEAAAAJ&hl=en" target="_blank">Lin Sun</a>
                </br>
                Samsung
              </td>

              <td class="organizer">
                <a href="https://yuxng.github.io/" target="_blank"><img src="photos/yu.png" width="120px" align="bottom" style="border-radius: 50%"></a>
                </br></br>
                <a href="https://yuxng.github.io/" target="_blank">Yu Xiang</a>
                </br>
                NVIDIA
              </td>

              <td class="organizer">
                <a href="https://www.cim.mcgill.ca/~dudek/" target="_blank"><img src="photos/greg.jpg" width="120px" align="bottom" style="border-radius: 50%"></a>
                </br></br>
                <a href="https://www.cim.mcgill.ca/~dudek/" target="_blank">Greg Dudek</a>
                </br>
                McGill / Samsung
              </td>
            </tr>
          </tbody>
        </table>
      </div>

      <div class="row section">
        <center><h3>Sponsor</h3><hr></center>
        <center>
          <a href="https://www.samsung.com/us/ssic/" target="_blank">
            <img src="./images/samsung_logo.png" class="img-sponsor">
          </a>
        </center>
      </div>

      <div class="row section">
        <center><h3>Contact</h3><hr></center>
        For further information, please contact us at <b>rss20vlrrm [AT] gmail [DOT] com</b>
      </div>

    </div>

  </body>

</html>
